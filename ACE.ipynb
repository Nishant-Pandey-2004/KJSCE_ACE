{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLI8iACFCuGR",
        "outputId": "10c7ea41-81eb-4b39-ef24-6a076730980a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📂 Loading data...\n",
            "⚙️ Preprocessing data...\n",
            "🔧 Preparing features...\n",
            "🛠️ Training base models...\n",
            "🧠 Training meta-model...\n",
            "\n",
            "🧠 Stacking Ensemble Model Performance:\n",
            "📉 Mean Squared Error: 25.16\n",
            "📊 Root Mean Squared Error: 5.02\n",
            "🎯 R² Score: 1.00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "class RetailPredictor:\n",
        "    def __init__(self):\n",
        "        self.label_encoders = {}\n",
        "        self.feature_preprocessor = None\n",
        "        self.rf_model = None\n",
        "        self.xgb_model = None\n",
        "        self.dl_model = None\n",
        "        self.meta_model = None\n",
        "\n",
        "    def preprocess_features(self, df):\n",
        "        \"\"\"\n",
        "        Preprocess the retail dataset with improved feature engineering\n",
        "        \"\"\"\n",
        "        data = df.copy()\n",
        "\n",
        "        # Handle outliers\n",
        "        Q1 = data['Sales'].quantile(0.25)\n",
        "        Q3 = data['Sales'].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        data = data[(data['Sales'] >= Q1 - 1.5 * IQR) & (data['Sales'] <= Q3 + 1.5 * IQR)]\n",
        "\n",
        "        # Create ratio features\n",
        "        data['Profit_Ratio'] = data['Profit'] / data['Sales']\n",
        "        data['Discount_Impact'] = data['Sales'] * (1 - data['Discount'])\n",
        "\n",
        "        # Encode categorical variables\n",
        "        categorical_cols = ['Category', 'Sub Category', 'City', 'Region', 'State']\n",
        "        for col in categorical_cols:\n",
        "            self.label_encoders[col] = LabelEncoder()\n",
        "            data[col] = self.label_encoders[col].fit_transform(data[col])\n",
        "\n",
        "        return data\n",
        "\n",
        "    def prepare_features(self, data):\n",
        "        \"\"\"\n",
        "        Prepare final feature set for modeling\n",
        "        \"\"\"\n",
        "        numeric_features = ['Discount', 'Profit_Ratio', 'Discount_Impact']\n",
        "        categorical_features = ['Category', 'Sub Category', 'City', 'Region', 'State']\n",
        "\n",
        "        # Scale numerical features\n",
        "        self.feature_preprocessor = RobustScaler()\n",
        "        data[numeric_features] = self.feature_preprocessor.fit_transform(data[numeric_features])\n",
        "\n",
        "        return numeric_features + categorical_features\n",
        "\n",
        "    def train_base_models(self, data, features):\n",
        "        \"\"\"\n",
        "        Train base models (RandomForest, XGBoost, and Deep Learning)\n",
        "        \"\"\"\n",
        "        X = data[features]\n",
        "        y = data['Sales']\n",
        "\n",
        "        # Split the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train Random Forest\n",
        "        self.rf_model = RandomForestRegressor(n_estimators=200, max_depth=15, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
        "        self.rf_model.fit(X_train, y_train)\n",
        "        rf_preds_train = self.rf_model.predict(X_train)\n",
        "        rf_preds_test = self.rf_model.predict(X_test)\n",
        "\n",
        "        # Train XGBoost\n",
        "        self.xgb_model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=10, random_state=42)\n",
        "        self.xgb_model.fit(X_train, y_train)\n",
        "        xgb_preds_train = self.xgb_model.predict(X_train)\n",
        "        xgb_preds_test = self.xgb_model.predict(X_test)\n",
        "\n",
        "        # Train Deep Learning Model\n",
        "        self.dl_model = Sequential([\n",
        "            Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "            Dropout(0.3),\n",
        "            Dense(64, activation='relu'),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dense(1, activation='linear')  # Regression output\n",
        "        ])\n",
        "        self.dl_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mse'])\n",
        "        self.dl_model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
        "        dl_preds_train = self.dl_model.predict(X_train).flatten()\n",
        "        dl_preds_test = self.dl_model.predict(X_test).flatten()\n",
        "\n",
        "        # Combine predictions as input for meta-model\n",
        "        X_train_meta = np.column_stack((rf_preds_train, xgb_preds_train, dl_preds_train))\n",
        "        X_test_meta = np.column_stack((rf_preds_test, xgb_preds_test, dl_preds_test))\n",
        "\n",
        "        return X_train_meta, X_test_meta, y_train, y_test\n",
        "\n",
        "    def train_meta_model(self, X_train_meta, X_test_meta, y_train, y_test):\n",
        "        \"\"\"\n",
        "        Train final meta-model using predictions from base models\n",
        "        \"\"\"\n",
        "        self.meta_model = Sequential([\n",
        "            Dense(32, activation='relu', input_shape=(X_train_meta.shape[1],)),\n",
        "            Dense(1, activation='linear')\n",
        "        ])\n",
        "        self.meta_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mse'])\n",
        "        self.meta_model.fit(X_train_meta, y_train, epochs=30, batch_size=8, verbose=0)\n",
        "\n",
        "        y_pred = self.meta_model.predict(X_test_meta).flatten()\n",
        "\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        print(\"\\n🧠 Stacking Ensemble Model Performance:\")\n",
        "        print(f\"📉 Mean Squared Error: {mse:.2f}\")\n",
        "        print(f\"📊 Root Mean Squared Error: {np.sqrt(mse):.2f}\")\n",
        "        print(f\"🎯 R² Score: {r2:.2f}\")\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "def analyze_sales_data(file_path):\n",
        "    \"\"\"\n",
        "    Analyze sales data using a stacking ensemble approach\n",
        "    \"\"\"\n",
        "    print(\"📂 Loading data...\")\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    predictor = RetailPredictor()\n",
        "\n",
        "    print(\"⚙️ Preprocessing data...\")\n",
        "    processed_data = predictor.preprocess_features(df)\n",
        "\n",
        "    print(\"🔧 Preparing features...\")\n",
        "    features = predictor.prepare_features(processed_data)\n",
        "\n",
        "    print(\"🛠️ Training base models...\")\n",
        "    X_train_meta, X_test_meta, y_train, y_test = predictor.train_base_models(processed_data, features)\n",
        "\n",
        "    print(\"🧠 Training meta-model...\")\n",
        "    y_pred = predictor.train_meta_model(X_train_meta, X_test_meta, y_train, y_test)\n",
        "\n",
        "    return predictor, processed_data, X_test_meta, y_test, y_pred\n",
        "\n",
        "# Run Ensemble Model\n",
        "predictor, processed_data, X_test, y_test, y_pred = analyze_sales_data('DMart_Grocery_Sales_-_Retail_Analytics_Dataset.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t3qekp2tC63o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 Prediction Results Summary:\n",
            "Average Prediction Accuracy: 54.13%\n",
            "Maximum Prediction Error: $2719.65\n",
            "Minimum Prediction Error: $197.17\n",
            "\n",
            "📋 Detailed Predictions:\n",
            "           Category Sub Category   Sales  Predicted_Sales  Prediction_Accuracy\n",
            "0         Furniture       Chairs 4672.11          1952.47                41.79\n",
            "1   Office Supplies      Storage 1790.29          1203.57                67.23\n",
            "2        Technology       Phones 3724.98          1633.82                43.86\n",
            "3         Furniture       Tables 4552.76          2325.29                51.07\n",
            "4   Office Supplies      Binders 1934.55          1134.44                58.64\n",
            "5        Technology  Accessories 4247.90          1935.01                45.55\n",
            "6         Furniture       Chairs 4137.47          2237.10                54.07\n",
            "7   Office Supplies      Storage 1305.90           916.74                70.20\n",
            "8        Technology       Phones 2506.18          1252.68                49.98\n",
            "9         Furniture       Tables 4981.11          2332.32                46.82\n",
            "10  Office Supplies      Binders 2666.61          1335.89                50.10\n",
            "11       Technology  Accessories 3993.24          2186.59                54.76\n",
            "12        Furniture       Phones  359.57           556.74                45.17\n",
            "13  Office Supplies      Storage 3035.24          1682.26                55.42\n",
            "14       Technology       Chairs 1244.49           961.19                77.24\n"
          ]
        }
      ],
      "source": [
        "def create_test_data():\n",
        "    return pd.DataFrame({\n",
        "        'Category': ['Furniture', 'Office Supplies', 'Technology'] * 5,\n",
        "        'Sub Category': ['Chairs', 'Storage', 'Phones', 'Tables', 'Binders', 'Accessories'] * 2 + ['Phones', 'Storage', 'Chairs'],\n",
        "        'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'] * 3,\n",
        "        'Region': ['East', 'West', 'Central', 'South', 'West'] * 3,\n",
        "        'State': ['NY', 'CA', 'IL', 'TX', 'AZ'] * 3,\n",
        "        'Sales': np.random.uniform(100, 5000, 15),\n",
        "        'Discount': np.random.uniform(0, 0.5, 15),\n",
        "        'Profit': np.random.uniform(10, 1000, 15)\n",
        "    })\n",
        "\n",
        "def test_predictor(predictor, test_data):\n",
        "    \"\"\"\n",
        "    Test the trained predictor on new data\n",
        "    \"\"\"\n",
        "    # Preprocess the test data\n",
        "    processed_test = predictor.preprocess_features(test_data)\n",
        "    features = predictor.prepare_features(processed_test)\n",
        "    \n",
        "    # Get predictions from base models\n",
        "    X_test = processed_test[features]\n",
        "    rf_preds = predictor.rf_model.predict(X_test)\n",
        "    xgb_preds = predictor.xgb_model.predict(X_test)\n",
        "    dl_preds = predictor.dl_model.predict(X_test).flatten()\n",
        "    \n",
        "    # Combine predictions for meta-model\n",
        "    X_test_meta = np.column_stack((rf_preds, xgb_preds, dl_preds))\n",
        "    \n",
        "    # Get final predictions\n",
        "    final_predictions = predictor.meta_model.predict(X_test_meta).flatten()\n",
        "    \n",
        "    # Add predictions to original data for comparison\n",
        "    results = test_data.copy()\n",
        "    results['Predicted_Sales'] = final_predictions\n",
        "    results['Prediction_Difference'] = results['Predicted_Sales'] - results['Sales']\n",
        "    results['Prediction_Accuracy'] = (1 - abs(results['Prediction_Difference'] / results['Sales'])) * 100\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Generate and test new data\n",
        "test_data = create_test_data()\n",
        "results = test_predictor(predictor, test_data)\n",
        "\n",
        "# Print summary statistics\n",
        "print(\"\\n📊 Prediction Results Summary:\")\n",
        "print(f\"Average Prediction Accuracy: {results['Prediction_Accuracy'].mean():.2f}%\")\n",
        "print(f\"Maximum Prediction Error: ${abs(results['Prediction_Difference']).max():.2f}\")\n",
        "print(f\"Minimum Prediction Error: ${abs(results['Prediction_Difference']).min():.2f}\")\n",
        "\n",
        "# Display detailed results\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "print(\"\\n📋 Detailed Predictions:\")\n",
        "print(results[['Category', 'Sub Category', 'Sales', 'Predicted_Sales', 'Prediction_Accuracy']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 Model Performance Metrics:\n",
            "Root Mean Square Error: $694.40\n",
            "Mean Absolute Error: $631.55\n",
            "Mean Absolute Percentage Error: 66.07%\n",
            "Average Prediction Accuracy: 33.93%\n",
            "\n",
            "📋 Detailed Predictions:\n",
            "      Category  Sub Category  City  Actual_Sales  Predicted_Sales  \\\n",
            "2275         0             3     6           611          1309.61   \n",
            "1498         4            19     7          1422          1416.66   \n",
            "5613         3            18     9          1419          2240.83   \n",
            "7685         5             8     7          1966          2469.67   \n",
            "7782         1            13    17          2234          1704.93   \n",
            "8            0             1    19           791          1388.57   \n",
            "9968         6            16     1          1981          2481.31   \n",
            "9853         4            17     8           860          2066.84   \n",
            "2055         3             0     8          1331           661.15   \n",
            "251          1            13     5           531          1313.43   \n",
            "\n",
            "      Prediction_Accuracy  \n",
            "2275               -14.34  \n",
            "1498                99.62  \n",
            "5613                42.08  \n",
            "7685                74.38  \n",
            "7782                76.32  \n",
            "8                   24.45  \n",
            "9968                74.74  \n",
            "9853               -40.33  \n",
            "2055                49.67  \n",
            "251                -47.35  \n",
            "\n",
            "📈 Prediction Range Analysis:\n",
            "Minimum Actual Sales: $531.00\n",
            "Maximum Actual Sales: $2234.00\n",
            "Minimum Predicted Sales: $661.15\n",
            "Maximum Predicted Sales: $2481.31\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def sample_test_data(original_df, sample_size=10, random_state=42):\n",
        "    \"\"\"\n",
        "    Randomly sample data points from the original dataset\n",
        "    \"\"\"\n",
        "    # Create a holdout set that wasn't used in training\n",
        "    _, test_holdout = train_test_split(original_df, test_size=0.1, random_state=random_state)\n",
        "    \n",
        "    # Randomly sample from the holdout set\n",
        "    test_sample = test_holdout.sample(n=sample_size, random_state=random_state)\n",
        "    return test_sample\n",
        "\n",
        "def test_predictor(predictor, test_data):\n",
        "    \"\"\"\n",
        "    Test the trained predictor on sampled data\n",
        "    \"\"\"\n",
        "    # Store original sales for comparison\n",
        "    original_sales = test_data['Sales'].copy()\n",
        "    \n",
        "    # Preprocess the test data\n",
        "    processed_test = predictor.preprocess_features(test_data)\n",
        "    features = predictor.prepare_features(processed_test)\n",
        "    \n",
        "    # Get predictions from base models\n",
        "    X_test = processed_test[features]\n",
        "    rf_preds = predictor.rf_model.predict(X_test)\n",
        "    xgb_preds = predictor.xgb_model.predict(X_test)\n",
        "    dl_preds = predictor.dl_model.predict(X_test).flatten()\n",
        "    \n",
        "    # Combine predictions for meta-model\n",
        "    X_test_meta = np.column_stack((rf_preds, xgb_preds, dl_preds))\n",
        "    \n",
        "    # Get final predictions\n",
        "    final_predictions = predictor.meta_model.predict(X_test_meta).flatten()\n",
        "    \n",
        "    # Create results DataFrame\n",
        "    results = test_data[['Category', 'Sub Category', 'City', 'Region', 'State', 'Discount', 'Profit']].copy()\n",
        "    results['Actual_Sales'] = original_sales\n",
        "    results['Predicted_Sales'] = final_predictions\n",
        "    results['Prediction_Difference'] = results['Predicted_Sales'] - results['Actual_Sales']\n",
        "    results['Prediction_Accuracy'] = (1 - abs(results['Prediction_Difference'] / results['Actual_Sales'])) * 100\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Sample and test data\n",
        "test_data = sample_test_data(processed_data, sample_size=10)\n",
        "results = test_predictor(predictor, test_data)\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "mse = np.mean(results['Prediction_Difference'] ** 2)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = np.mean(abs(results['Prediction_Difference']))\n",
        "mape = np.mean(abs(results['Prediction_Difference'] / results['Actual_Sales'])) * 100\n",
        "\n",
        "print(\"\\n📊 Model Performance Metrics:\")\n",
        "print(f\"Root Mean Square Error: ${rmse:.2f}\")\n",
        "print(f\"Mean Absolute Error: ${mae:.2f}\")\n",
        "print(f\"Mean Absolute Percentage Error: {mape:.2f}%\")\n",
        "print(f\"Average Prediction Accuracy: {results['Prediction_Accuracy'].mean():.2f}%\")\n",
        "\n",
        "# Display detailed results\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "print(\"\\n📋 Detailed Predictions:\")\n",
        "print(results[['Category', 'Sub Category', 'City', 'Actual_Sales', 'Predicted_Sales', 'Prediction_Accuracy']])\n",
        "\n",
        "# Print range of predictions\n",
        "print(\"\\n📈 Prediction Range Analysis:\")\n",
        "print(f\"Minimum Actual Sales: ${results['Actual_Sales'].min():.2f}\")\n",
        "print(f\"Maximum Actual Sales: ${results['Actual_Sales'].max():.2f}\")\n",
        "print(f\"Minimum Predicted Sales: ${results['Predicted_Sales'].min():.2f}\")\n",
        "print(f\"Maximum Predicted Sales: ${results['Predicted_Sales'].max():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
